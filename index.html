<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Whisper ASR Recorder</title>
  <!-- Material Icons -->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <style>
    body {
      font-family: Arial, sans-serif;
      background: #f0f8ff;
      display: flex;
      align-items: center;
      justify-content: center;
      height: 100vh;
      margin: 0;
    }
    .card {
      background: #fff;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
      border-radius: 12px;
      padding: 30px;
      text-align: center;
      width: 90%;
      max-width: 600px;
    }
    #recordButton {
      width: 150px;
      height: 150px;
      border-radius: 50%;
      border: none;
      font-size: 20px;
      color: white;
      background: #4CAF50;
      cursor: pointer;
      transition: all 0.3s ease;
      outline: none;
      margin-bottom: 20px;
    }
    #recordButton:hover {
      transform: scale(1.05);
    }
    #recordButton.recording {
      background: #f44336;
      animation: pulse 2s infinite;
    }
    .status-buttons {
      display: flex;
      justify-content: center;
      gap: 20px;
      margin-bottom: 20px;
    }
    .status-button {
      padding: 10px 20px;
      border: none;
      border-radius: 20px;
      background: #e0e0e0;
      color: #666;
      opacity: 0.5;
      cursor: pointer;
      transition: all 0.3s ease;
      display: flex;
      align-items: center;
      gap: 8px;
    }
    .status-button.active {
      opacity: 1;
      background: #4CAF50;
      color: white;
    }
    .status-button.processing {
      opacity: 1;
      background: #2196F3;
      color: white;
      animation: bounce 1s infinite;
    }
    .content-box {
      margin-top: 20px;
      padding: 15px;
      border: 2px solid #ccc;
      border-radius: 8px;
      background: #f9f9f9;
      font-size: 18px;
      min-height: 150px;
      text-align: left;
      word-wrap: break-word;
      transition: all 0.3s ease;
      white-space: pre-wrap; /* This preserves formatting */
    }
    .content-box.processed {
      border-color: #4CAF50;
    }
    @keyframes pulse {
      0% { transform: scale(1); }
      50% { transform: scale(1.05); }
      100% { transform: scale(1); }
    }
    @keyframes bounce {
      0%, 100% { transform: translateY(0); }
      50% { transform: translateY(-5px); }
    }
    /* Message styling */
    #message {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background: #4CAF50;
      color: white;
      padding: 10px 20px;
      border-radius: 4px;
      opacity: 0;
      transition: opacity 0.3s;
    }
    .retry-button {
      display: none;
      margin-top: 10px;
      padding: 8px 16px;
      background: #ff9800;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      transition: all 0.3s ease;
      display: flex;
      align-items: center;
      gap: 4px;
      margin-left: auto;
      margin-right: auto;
    }

    .retry-button:hover {
      background: #f57c00;
    }
  </style>
</head>
<body>
  <div class="card">
    <button id="recordButton">
      Record
    </button>
    
    <div class="status-buttons">
      <button class="status-button" id="transcribeBtn">
        <span class="material-icons">record_voice_over</span>
        Transcribe
      </button>
      <button class="status-button" id="processBtn">
        <span class="material-icons">auto_fix_high</span>
        Process
      </button>
    </div>

    <div class="content-box" id="content">Click record to start...</div>
    <button id="retryButton" class="retry-button">
      <span class="material-icons">refresh</span>
      Retry
    </button>
  </div>
  <div id="message">Copied to clipboard!</div>

  <script>
    let mediaRecorder;
    let recordedChunks = [];
    let isRecording = false;
    let stream;
    let currentText = '';
    let processedText = '';

    const recordButton = document.getElementById('recordButton');
    const transcribeBtn = document.getElementById('transcribeBtn');
    const processBtn = document.getElementById('processBtn');
    const contentBox = document.getElementById('content');
    const messageDiv = document.getElementById('message');
    const retryButton = document.getElementById('retryButton');

    // Toggle between raw and processed text
    transcribeBtn.addEventListener('click', () => {
      if (currentText) {
        contentBox.innerHTML = currentText;
        contentBox.classList.remove('processed');
        transcribeBtn.classList.add('active');
        processBtn.classList.remove('active');
      }
    });

    processBtn.addEventListener('click', () => {
      if (processedText) {
        contentBox.innerHTML = processedText;
        contentBox.classList.add('processed');
        processBtn.classList.add('active');
        transcribeBtn.classList.remove('active');
      }
    });

    async function startRecording() {
      // Reset UI
      contentBox.textContent = 'Recording...';
      currentText = '';
      processedText = '';
      transcribeBtn.classList.remove('active', 'processing');
      processBtn.classList.remove('active', 'processing');
      messageDiv.style.opacity = 0;

      try {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        recordedChunks = [];
        mediaRecorder.addEventListener('dataavailable', event => {
          if (event.data.size > 0) recordedChunks.push(event.data);
        });
        mediaRecorder.addEventListener('stop', onRecordingStop);
        mediaRecorder.start();
        recordButton.classList.add('recording');
        recordButton.textContent = 'Stop';
        isRecording = true;
      } catch (err) {
        console.error('Error accessing microphone:', err);
        contentBox.textContent = 'Error accessing microphone';
      }
    }

    async function stopRecording() {
      mediaRecorder.stop();
      stream.getTracks().forEach(track => track.stop());
      recordButton.classList.remove('recording');
      recordButton.textContent = 'Record';
      isRecording = false;
    }

    async function onRecordingStop() {
      const audioBlob = new Blob(recordedChunks, { type: 'audio/webm' });
      const formData = new FormData();
      formData.append('audio_file', audioBlob, 'recording.webm');

      try {
        // Start transcription
        transcribeBtn.classList.add('processing');
        contentBox.textContent = 'Transcribing...';

        const response = await fetch('/asr?encode=true&task=transcribe&language=en&output=json', {
          method: 'POST',
          body: formData
        });
        
        if (!response.ok) throw new Error('Transcription failed');
        const result = await response.json();
        currentText = result.text || 'No transcription available';
        
        // Show transcription
        contentBox.innerHTML = currentText;
        transcribeBtn.classList.remove('processing');
        transcribeBtn.classList.add('active');

        // Start processing
        processBtn.classList.add('processing');
        contentBox.textContent = 'Processing...';

        // Process with Ollama
        processedText = await processWithOllama(currentText);
        
        // Show processed text
        contentBox.innerHTML = processedText;
        contentBox.classList.add('processed');
        processBtn.classList.remove('processing');
        processBtn.classList.add('active');
        transcribeBtn.classList.remove('active');

        // Copy to clipboard and show message
        await navigator.clipboard.writeText(processedText);
        messageDiv.style.opacity = 1;
        setTimeout(() => messageDiv.style.opacity = 0, 2000);

      } catch (error) {
        console.error('Error:', error);
        contentBox.textContent = 'Error during transcription or processing';
        transcribeBtn.classList.remove('processing');
        processBtn.classList.remove('processing');
        retryButton.style.display = 'inline-block';
      }
    }

    async function processWithOllama(prompt) {
      try {
        const response = await fetch('http://localhost:11434/api/generate', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            model: 'qwen2.5',
            system: "You are a tool - atext processing assistant. Take the raw transcribed text and: \n" +
                    "1. Fix any grammar, spelling or trascribing issues\n" +
                    "2. Add proper punctuations\n" +
                    "3. Format into clean, readable paragraphs\n" +
                    "4. No meaning or intent changes. Try to do minimal modifications - your focus is formatting! \n" +
                    "6. You identify bold, italic, lists, code-blocks, code, paragraphs, headings, linebreaks, etc.\n" +
                    "Return only the processed text without any explanations or meta-commentary.",
            prompt: `Raw Transcribed Text: ${prompt}`,
            stream: false
          })
        });
        
        if (!response.ok) throw new Error('Ollama request failed');
        const data = await response.json();
        console.log(data);
        return data.response?.trim() ?? 'Error processing text.';
      } catch (err) {
        console.error('Error calling Ollama:', err);
        return 'Error processing text.';
      }
    }

    recordButton.addEventListener('click', () => {
      if (!isRecording) {
        startRecording();
      } else {
        stopRecording();
      }
    });

    retryButton.addEventListener('click', async () => {
      retryButton.style.display = 'none';
      if (recordedChunks.length > 0) {
        await onRecordingStop();
      }
    });
  </script>
</body>
</html>
